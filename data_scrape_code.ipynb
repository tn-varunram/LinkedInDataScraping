{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Consider reading the 'README.md' file for more clarity on this program/code.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs\n",
    "wd = webdriver.Chrome(executable_path=r'C:\\Users\\Sravan Kumar\\chromedriver.exe')\n",
    "wd.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinkedIn SignIn Page\n",
    "wd.get('https://www.linkedin.com/login?fromSignIn=true&trk=guest_homepage-basic_nav-header-signin')\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u=wd.find_element_by_name('session_key')\n",
    "u.send_keys('Email Input') #Give your LinkedIn username or email here\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=wd.find_element_by_name('session_password')\n",
    "p.send_keys('Password Input') #Give your LinkedIn password here\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#signin button\n",
    "wd.find_element_by_xpath('//button[@type=\"submit\"]').click()\n",
    "time.sleep(5)\n",
    "\n",
    "#Cosider the following lines only if you don't given the phone number for the given LinkedIn Account\n",
    "# skip = wd.find_element_by_class_name('secondary-action')\n",
    "# skip.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Give the location input to search profiles in that area/region\n",
    "loc1 = str(input(\"Enter the location to search people in that area: \"))\n",
    "url = 'https://www.linkedin.com/search/results/people/?keywords='+loc1+'&origin=SWITCH_SEARCH_VERTICAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Profile URLs Data\n",
    "\n",
    "profile_urls = []\n",
    "for i in range(5):\n",
    "    url = 'https://www.linkedin.com/search/results/people/?keywords='+loc1+'&origin=SWITCH_SEARCH_VERTICAL'+'&page='+str(i+1)\n",
    "    l=wd.get(url)\n",
    "    time.sleep(5)\n",
    "    l=wd.page_source\n",
    "    soup = bs(l, 'lxml')\n",
    "    tags = soup.find_all('a')\n",
    "    temp = 0\n",
    "    for tag in tags:\n",
    "        if(tag.get('class') == ['search-result__result-link', 'ember-view']):\n",
    "            time.sleep(1)\n",
    "            temp+=1\n",
    "            if(temp%2==0):\n",
    "                p_url = 'https://www.linkedin.com/' + tag.get('href')\n",
    "                profile_urls.append(p_url)\n",
    "                print(p_url)\n",
    "                print(\"<-------------------------------------------------------------------------------------------------->\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping in-profile data\n",
    "\n",
    "p_len = len(profile_urls)\n",
    "data = {}\n",
    "data_no = 0\n",
    "for z in range(p_len):\n",
    "    profile = profile_urls[z]\n",
    "    profile_details=wd.get(profile)\n",
    "    time.sleep(5)\n",
    "    profile_details=wd.page_source\n",
    "    details = open('d1.html', 'w', encoding = 'utf8')\n",
    "    details.write(profile_details)\n",
    "    details.close()\n",
    "    r = open('d1.html', 'r+', encoding = 'utf8')\n",
    "    soup = bs(r)\n",
    "    r.close()\n",
    "    try:\n",
    "        time.sleep(5)\n",
    "        #name [li tag] class = t-24\n",
    "        nameLine = soup.find('li', {'class' : 't-24'})\n",
    "        name = nameLine.get_text().lstrip().rstrip()\n",
    "    except:\n",
    "        name = 'N/A'\n",
    "#_________________________________________________________________________________________________________\n",
    "    try:\n",
    "        #position [h2 tag] class = t-18\n",
    "        positionLine = soup.find('h2', {'class' : 't-18'})\n",
    "        position = positionLine.get_text().lstrip().rstrip()\n",
    "    except:\n",
    "        position = 'N/A'\n",
    "#_________________________________________________________________________________________________________\n",
    "    try:\n",
    "        #address [li tag] class = t-16\n",
    "        addressLine = soup.find('li', {'class' : \"t-16 t-black t-normal inline-block\"})\n",
    "        address = addressLine.get_text().lstrip().rstrip()\n",
    "    except:\n",
    "        address = 'N/A'\n",
    "#_________________________________________________________________________________________________________\n",
    "    try:\n",
    "        #connections [span tag] class = t-16\n",
    "        connectionsLine = soup.find('span', {'class' : 't-16 t-black t-normal'})\n",
    "        connections = connectionsLine.get_text().lstrip().rstrip()\n",
    "    except:\n",
    "        connections = 'N/A'\n",
    "#_________________________________________________________________________________________________________\n",
    "    try:\n",
    "        #skills\n",
    "        skillsPage = profile + 'skills'\n",
    "        skills_details=wd.get(skillsPage)\n",
    "        time.sleep(5)\n",
    "        skills_details=wd.page_source\n",
    "        skill_bs = bs(skills_details)\n",
    "        skillsLine = skill_bs.find_all('p', {'class' : 't-16 t-black t-bold pv1'})\n",
    "        skills = ''\n",
    "        for skill in skillsLine:\n",
    "            skills = skills + \" | \" + skill.get_text() \n",
    "        skills = skills + \" | \"\n",
    "    except:\n",
    "        skills = 'N/A'\n",
    "#_________________________________________________________________________________________________________\n",
    "    try:\n",
    "        email = ''\n",
    "        #email\n",
    "        e=get_soup(profile+'detail/contact-info/')\n",
    "        email=get_email(e).lstrip().rstrip()\n",
    "    except:\n",
    "        email = 'N/A'\n",
    "#_________________________________________________________________________________________________________\n",
    "    try:\n",
    "        #interests\n",
    "        interestsPage = profile + 'detail/interests/companies/'\n",
    "        interests_details=wd.get(interestsPage)\n",
    "        time.sleep(5)\n",
    "        interests_details=wd.page_source\n",
    "        company_bs = bs(interests_details)\n",
    "        companyLine = company_bs.find_all('span', {'class' : 'pv-entity__summary-title-text'})\n",
    "        companies = ''\n",
    "        for company in companyLine:\n",
    "            companies = companies + \" | \" + company.get_text() \n",
    "        companies = companies + \" | \"\n",
    "    except:\n",
    "        companies = 'N/A'   \n",
    "#_________________________________________________________________________________________________________\n",
    "    data_no += 1\n",
    "    data[data_no] = [name, email, position, address, connections, skills, companies, profile]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the data scraped into a CSV file named as \"profile_data.csv\"\n",
    "\n",
    "data_df = pd.DataFrame.from_dict(data, orient='index', columns = ['Name', 'Email ID', 'Position', 'Address', 'Connections Count', 'Skills', 'Companies Interested', 'Profile URL' ])\n",
    "data_df.to_csv('profile_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinkedIn Logout and Webdriver Abort action\n",
    "\n",
    "l=wd.get('https://www.linkedin.com/m/logout/')\n",
    "time.sleep(2)\n",
    "wd.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
